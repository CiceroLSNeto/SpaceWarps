%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Space Warps I: Experiment Design
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[useAMS,usenatbib,a4paper]{mn2e}
%% letterpaper
%% a4paper

\voffset=-0.6in

% Packages:
\input psfig.sty
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}

% Macros:
\input{macros.tex}
\input{addresses.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[\sw I]
{\SW: Crowd-sourcing the Discovery of Gravitational Lenses. 
I: System Design}
    
\author[The \SW Collaboration]{%
  The \SW Collaboration:
  % \input{authors.tex}
}

% This list is incomplete.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
             
\date{to be submitted to MNRAS? Not necessarily.}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}\pubyear{2012}

\maketitle           

\label{firstpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract} 


\end{abstract}

% Full list of options at http://www.journals.uchicago.edu/ApJ/instruct.key.html

\begin{keywords}
  gravitational lensing   --
  methods: statistical    
\end{keywords}

\setcounter{footnote}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

Scientific motivation. Applications of lenses: group-scale arcs,
galaxy-galaxy lenses, lensed quasars. 

Problem of rarity. Imaging surveys. Problem of purity/false positives.

Review of progress to date. Methods in SL2S, SQLS. Contrast with SLACS. 

Scaling to wide field era. Automated methods: problems. Need for good
training sets. Need for quality control: always present.

Novel solution: crowd-sourcing. Brief review of similar problems.
PlanetHunters. \sw as an experiment.

In this paper, we describe the \sw website, an online system that
enables crowd-sourced detection of gravitational lenses. 
Other papers in this series will present new gravitational lenses
discovered in our first imaging survey dataset, and investigate the
differences between lens detections made in \sw and those made with
automated techniques. Here, we try to answer the following questons:
\begin{itemize}

\item How reliably can we find gravitational lenses using the \sw
system? What is the completeness of the sample produced?

\item How noisy is the system? What is the purity of the sample
produced?

\item How accurately can gravitational lenses be located on the sky
during the identification process?

\item How quickly can lenses be detected, and non-lenses be rejected?
How many classifiers are needed per target, and how quickly can they
mobilise?

\end{itemize}

In \Sref{sec:design} we introduce the \sw system, describing and
explaining its various features. We then briefly 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiment Design}
\label{sec:design}

Unfamiliar objects: need to learn what lenses look like, fast. Rare
objects: need to be able to reject rapidly, and get through sample.
Confusion with non-lenses: further filtering via scientific discussion
and further classification (voting). 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Tutorial Material}
\label{sec:design:tutorial}

Learning what lenses do: Spotter's Guide and LensToy. Learning how
lenses work (science page, FAQ). 

Inline tutorial. Merge into stream. Instant feedback, positive and
negative. Anecdotal support for this.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{The Classification Interface}
\label{sec:design:classification}

Image presentation. Consistency in size and appearance. 

Interface fast due to pre-loading of images, and minimizing interaction.

Spotting lenses: Markers to be placed. Two reasons: first, to give good
feedback. Second, to improve quality of discussion later.

Quick dashboard provides simple ways to explore further: zoom, contrast
controls.

Non-lenses marked? Favourite button instead, enabling serendipitous
discovery of other interesting things, separate from lenses.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Collaborative Filtering with ``Talk''}
\label{sec:design:classification}

Feeding in collections, following online analysis. 
Taking subjects to Talk individually, too.

Mental modeling. Further inspection on Dashboard. Voting. 

Final sample generation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data}
\label{sec:data}

Training data and test data. Refer to Paper II for CFHTLS details.

Presentation of images. Arcsinh stretch, calibration. Approximately
optimized.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Identification Analysis}
\label{sec:IDanalysis}

In this section we outline our methodology for interpreting the
interactions of the volunteers with the identification interface.  Each
classification made is logged in a database, storing subject IDs,
(anonymous) volunteer IDs, a timestamp and the classification results. 
The {\it kind} of subject -- whether it is a training subject (a 
simulated lens or a known non-lens) or a test subject (an unseen image
drawn from the survey) -- is also recorded. For all subjects, the
positions of all Markers are recorded, in pixel coordinates. For
training subjects, we also store the ``classification'' of the subject
as a lens, or a non-lens, and also the type of object present in the
image. These types are summarized in \Tref{tab:objecttypes}. 
This classification is used to provide instant feedback, but is also the
basic measurement used in a probabilistic classification of every
subject based on all image views to date.

We perform a ``Pseudo-online'' analysis of the classifications, 
updating a probabilistic model of every (anonymous) volunteer's
expertise, and every subject (in both the training and test sets), on a
daily basis. This allows us to track the speed with which the crowd
learns about lenses, and also gives us a dynamic estimate of the
posterior probability for  any given  subject being a lens, given all
classifications of it. Assigning thresholds in this lens probability
allows us to make good decisions about whether or not to accept a
subject into the collection of candidates visible in \Talk, and also
whether or not to  carry on classifying a subject at all. 

In this paper we focus on the training data,  investigating  how the 
crowd's ability to identify gravitational lenses during the course of
the project, and the completeness and purity of the lens candidate
sample generated.

Where to describe probabilistic classifier stuff? Here or in an
appendix? Not sure.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Identification Results}
\label{sec:IDresults}

Understanding crowd, so we can help them learn faster. Understanding
images given the crowd, so we can find lenses.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Learned Behavior}
\label{sec:results:learning}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Sample completeness and purity}
\label{sec:results:learning}

Vary the acceptance and rejection thresholds, look at completeness and
purity as a function of this. How much time can be saved by retiring
subjects into candidate list or rejection list?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:discuss}

Challenges for future.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}
\label{sec:conclude}

We draw the following conclusions:

\begin{itemize} 

\item Ability to detect lenses

\item What we can say about the next steps

\end{itemize}

Summarize, end.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  ACKNOWLEDGMENTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}
 
\input{acknowledgments.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Probabilistic Classification Model}
\label{appendix:probmodel}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% MNRAS does not use bibtex, input .bbl file instead. 
% Generate this in the makefile using bubble script in scriptutils:

% bubble -f paper-lcr.tex references.bib 
% \input{paper-lcr.bbl}

\bibliographystyle{apj}
\bibliography{references}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{lastpage}
\bsp

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

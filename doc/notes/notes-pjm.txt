# ============================================================================
# 2013-04-07 (Sunday) 00:58 IST
#
# Get beta click database and start writing analysis code for it.

cd analysis/workspace

wget http://spacewarps.org.s3.amazonaws.com/data-export/spacewarps-2013-04-06_20-07-28.tar.gz

tar xvfz spacewarps-2013-04-06_20-07-28.tar.gz

ls spacewarps-2013-04-06_20-07-28/ouroboros_staging/
# spacewarp_classifications.bson          spacewarp_subjects.bson
# spacewarp_classifications.metadata.json spacewarp_subjects.metadata.json

# These are files to be read into a mongoDB, using mongodbrestore.

# Needs pymongo... pip install? Yep - done

# Also need binary installation of mongodb, from mongodb.org
# Downloaded to software, linked to ~/bin

mongorestore spacewarps-2013-04-06_20-07-28
# Sun Apr  7 01:23:48.133 kern.sched unavailable
# couldn't connect to [127.0.0.1] couldn't connect to server 127.0.0.1:27017

# Hmm. Looks beyond my pay grade.
# Try from python:

cd spacewarps-2013-04-06_20-07-28/
python ../../swap/mongodb.py

Traceback (most recent call last):
  File "../../swap/mongodb.py", line 23, in <module>
    m = MongoDB()
  File "../../swap/mongodb.py", line 13, in __init__
    self.client = MongoClient('localhost', 27017)
  File "/usr/local/Cellar/python/2.7.2/lib/python2.7/site-packages/pymongo/mongo_client.py", line 336, in __init__
    raise ConnectionFailure(str(e))
pymongo.errors.ConnectionFailure: could not connect to localhost:27017: [Errno 61] Connection refused

# Need to start mongodb server in the background:

mongod --dbpath . &

# Now python runs ok:

python ../../swap/mongodb.py
# Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_subjects.0')
# Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_classifications.0')

# What are these things?!
# OK, open up python session and start playing.

>>> import swap
>>> m = swap.MongoDB()
>>> m.subjects
Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_subjects')
>>> m.subjects.find()
<pymongo.cursor.Cursor object at 0x101220f50>

# Interesting.

>>> m.subjects.find_one({'zooniverse_id' : 'ASW0000002'})
{u'project_id': ObjectId('5101a1341a320ea77f000001'),
u'classification_count': 523, u'created_at': datetime.datetime(2013, 4,
4, 20, 29, 18, 949000), u'random': 0.5465496445414518, u'updated_at':
datetime.datetime(2013, 4, 4, 20, 29, 18, 975000), u'state':
u'complete', u'trending': 3, u'coords': [], u'location': {u'thumbnail':
u'', u'standard': u''}, u'zooniverse_id': u'ASW0000002',
u'workflow_ids': [ObjectId('5101a1361a320ea77f000002')], u'_id':
ObjectId('5101a1931a320ea77f000004'), u'tutorial': True, u'metadata':
{}}

# OK cool - here's a clue to the subject schema, and the metadata on subject
# ASW0000002.

# How about a non-tutorial one?
>>> m.subjects.find_one({'zooniverse_id' : 'ASW0000004'}) {u'_id':
ObjectId('515de29fe4bb216427000001'), u'classification_count': 13,
u'created_at': datetime.datetime(2013, 4, 4, 20, 29, 19, 372000),
u'activated_at': datetime.datetime(2013, 4, 4, 20, 32, 51, 886000),
u'updated_at': datetime.datetime(2013, 4, 4, 20, 29, 19, 398000),
u'random': 0.1047423015104475, u'project_id':
ObjectId('5101a1341a320ea77f000001'), u'state': u'active',
u'zooniverse_id': u'ASW0000004', u'workflow_ids':
[ObjectId('5101a1361a320ea77f000002')], u'location': {u'thumbnail':
u'http://www.spacewarps.org/subjects/thumbnail/CFHTLS_002_0530_gri.png',
u'standard':
u'http://www.spacewarps.org/subjects/standard/CFHTLS_002_0530_gri.png'},
u'group_id': ObjectId('5154a3783ae74086ab000001'), u'metadata': {u'id':
u'CFHTLS_002_0530'}}

# Nice! There's the actual image name, from Anu. And this URL is open -
# volunteers can grab those any time if they want to model them elsewhere.
# Just need to expose that on the site somewhere.

# Anyway, what about classifications?

>>> m.classifications.find_one()
{u'_id': ObjectId('515de3a9390c056085000416'), u'created_at':
datetime.datetime(2013, 4, 4, 20, 33, 45), u'updated_at':
datetime.datetime(2013, 4, 4, 20, 33, 45, 885000), u'user_ip':
u'163.1.174.106', u'workflow_id': ObjectId('5101a1361a320ea77f000002'),
u'subjects': [], u'subject_ids': [ObjectId('515dd45de4bb21597c00026c')],
u'project_id': ObjectId('5101a1341a320ea77f000001'), u'annotations':
[{u'finished_at': u'Thu, 04 Apr 2013 20:32:19 GMT', u'started_at': u'Thu, 04
Apr 2013 19:57:45 GMT'}, {u'user_agent': u'Mozilla/5.0 (Macintosh; Intel Mac
OS X 10_7_5) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.43
Safari/537.31'}]}

>>> m.classifications.find({'_id':'515de3a9390c056085000416'})
# <pymongo.cursor.Cursor object at 0x10122c050>

# Hmm. A cursor seems to be some sort of cursor. Might need a bit of help
# learning how this works!

# Plan:
#
# Make a list of operations that I want to do,
# and ask for a suggested example command from Amit?
#
# 1) Return a list of users as an array of strings
#
# 2) For a given user, return the IDs of all the training subjects they classified
#     Presumably this array will be time-ordered?
#
# 3) For a given user and training subject ID, return the value 1 if they succeeded in recognising it, 0 if not

# Issued.


# 2013-04-18 (Thursday) 12:04 BST
#
# datetime objects are interesting! See http://docs.python.org/2/library/datetime.html
#
# >>> import datetime
# >>> print datetime.datetime(2013, 4, 4, 20, 29, 18, 949000)
# 2013-04-04 20:29:18.949000
# >>> t1 = datetime.datetime(2013, 4, 4, 20, 29, 18, 949000)
# >>> t2 = datetime.datetime(2013, 4, 5, 8, 15, 23, 543000)
# >>> t2 - t1
# datetime.timedelta(0, 42364, 594000)
# >>> t1 > t2
# False
# >>> t1 <= t2
# True

# Perfect!

# ============================================================================
# 2013-04-22 (Monday) 23:24 BST

# Getting data out of mongodb is not so intuitive. Wrapped it up in
# python so that I can just do, eg

cd workspace
python ../swap/mongodb.py

# But I cannot do even the most basic things - so I've written down what
# I want to do in plausible python, for Amit to advise on!

# ============================================================================
# 2013-04-24 (Wednesday) 10:18 BST
#
# Great session with Amit yesterday solving all my db access problems!
# He says that on the Zooniverse system, the correct db is always online,
# so we should just connect to the client. That means that all of this
# wrapper I wrote is redundant - but I preserve it here, for reference:

#     self.dumpname = dumpname
#
#     # Keep a record of what goes on:
#     self.logfilename = os.getcwd()+'/'+self.dumpname+'.log'
#     self.logfile = open(self.logfilename,"w")
#
#     # Start the Mongo server in the background:
#     subprocess.call(["mongorestore",self.dumpname],stdout=self.logfile,stderr=self.logfile)
#     os.chdir(self.dumpname)
#     self.cleanup()
#     self.process = subprocess.Popen(["mongod","--dbpath","."],stdout=self.logfile,stderr=self.logfile)
#
#     # Check everything is working:
#     if self.process.poll() == None: print "MongoDB: server is up and running"
#
#     # Connect to the Mongo:
#     self.client = MongoClient('localhost', 27017)
#     self.db = self.client['ouroboros_staging']
#
#     self.subjects = self.db['spacewarp_subjects']
#     self.classifications = self.db['spacewarp_classifications']

# Followed by, later,
#     m.terminate()

# Worked example gives the following result, from the initial beta DB:

# Counted  7564  classifications, that each look like:
# ('2013-04-06 19:54:42.146000', '5065ff08d10d244cd10029ba', '515de2efe4bb21642700019a', 'test', 'NOT')

# ============================================================================
# 2013-04-29 (Monday) 17:03 BST

# OK, got SWAP working in its simplest incarnation.
# REady to do some experiments!

# Standard setup is this on: agents learn, but set PD=PL=50%, initially.
SWAP.py CFHTLS-beta_P50.config

# Aprajita asks, do we have to learn? Why not assume one set of P's and
# stick with them? Get off to a fsater start?
SWAP.py CFHTLS-beta_no-learning_P50.config
# Random classifiers get nowhere!

SWAP.py CFHTLS-beta_no-learning_P90.config
# Big jumps up and down in probability, lots of false positives.


# OK, so back to learning. How about we be less pessimistic about people's
# talents?
SWAP.py CFHTLS-beta_P90.config
# Not bad - Christmas tree is broader. FP rate higher, but got some sims in
# the detection zone now.

# More measured. Crowd divided between two groups?
#    The Herd: PD = 0.9, PL = U(0:1)
# Enthusiasts: PD = U(0.2:0.6), PL = U(0.6:1.0)
SWAP.py CFHTLS-beta_P70.config


# One issue with this LENS or NOT analysis is the hard edged estimation of PD
# and PL. Early classifications can have a significant impact... Hmm. 70-70
# seems like a reasonable starting point.


# Wishlist for mock survey:

# - Difficulty variation              DONE
# - PD, PL capped at 0.99             DONE
# - Realistic PDFs for Nc, PD, PL     DONE

# ============================================================================
# 2013-05-06 (Monday) 12:40 BST

# Wishlist for mock survey (continued):

# - Completeness, purity calculated   DONE 2013-05-06
# - Detected/rejected subjects        DONE 2013-05-06
# - Retired/promoted subjects         DONE 2013-05-06
# - Candidate IDs output              DONE 2013-05-06

# OK, great! Now we just need to be able to do low cost
# batch processing.


# ============================================================================
# 2013-05-07 (Tuesday) 09:43 BST

# Testing new database!

# Download:

set url = "https://zooniverse-code.s3.amazonaws.com/databases/2013-05-07/ouroboros_projects/spacewarp_2013-05-07.tar.gz?AWSAccessKeyId=AKIAJHHZ7KLFECQKTS7A&Expires=1368548396&Signature=as2nCaTgD9ctFLIHZrxj%2FrnQJoo%3D"

set dbfile = `echo "$url" | cut -d '?' -f1 | cut -d'/' -f7`
set logfile = ${dbfile:r:r}.wget.log
wget -O $dbfile "$url" >& $logfile

# Unpack:
tar xvfz $dbfile

set db = $dbfile:r:r

# First need to kill any old servers:
set pid = `ps -e | grep 'mongod --dbpath' | \
                   grep -v 'grep' | head -1 | awk '{print $1}'`
if ($#pid > 0) kill $pid

# Start new mongo server in its own directory, out of the way:
mkdir -p mongo
chdir mongo
mongod --dbpath . &
chdir ..

# Now restore the new database:
mongorestore --drop --db ouroboros_staging $db

# Probably should script this? Maybe?


# Try running SWAP:

SWAP.py CFHTLS-test.config >& CFHTLS-test.log

# SWAP: interpreting classifications...
# SWAP: total no. of classifications processed:  0


# Scripted! Just need to download db tarball manually:

SWIPE.csh spacewarp_2013-05-07.tar.gz


# ============================================================================
# 2013-05-07 (Tuesday) 18:36 BST

# Control of retirement from afar! Coooooool.

# Email from Michael Parrish:


# Hi Phil,
# 
# I'm attaching an example administration client script (in python) along
# with the documentation for administration endpoints. The script depends
# on the requests library, which you can install with `pip install
# requests`.
# 
# The admin account in the script is active -- feel free to
# retire/activate some subjects to make sure it's working for you.
# 
# Since this is all new code, there may still be some rough edges to work
# through, so please let me know if you have questions/problems.
# 
# -Michael
# 
# 
# 
# Administration:
# 
# Administration requests are authenticated with a combination of a
# password, a private key, a public key, and a sequence identifier.
# 
# 
# Administrators:
# 
# Accounts are created by request. A password, and private key will be
# supplied.
# 
# 
# Session:
# 
# A session begins by logging in with a POST request to /admin/login with
# { name: 'your admin name', password: 'your admin password' }
# 
# A successful login responds with a new public_key.
# 
# 
# Requests:
# 
# After establishing a session, requests can be made by signing each
# request with the name of the administrator and request key.
# 
# Request keys are generated by combining the public and private keys as
# well as a sequence identifier.
# 
# At the beginning of a session, the sequence identifier is 1. Each
# request increments this number.
# 
# In the case of an unauthorized request, sequence identifiers will no
# longer match causing the session to terminate.
# 
# If a session terminates, a new login request must be sent to restart the
# session with a new public key.
# 
# 
# Login Limits:
# 
# More than 10 unsuccessful login attempts within an hour will temporarily
# block logins by the administrator account. More than 100 unsuccessful
# login attempts within an hour will disable the administrator account. A
# developer will have to reactivate it.
# 
# Requests:
# 
# Administration requests are rate limited to less than 1,000 per hour.
# All requests, successful or not, are logged for security purposes.
# 
# Example code:
# 
# Subject Administration
# 
# Method  Action      Path                                                Params
# PUT     activate    /admin/projects/:project_id/subjects/:id/activate   { }
# PUT     retire      /admin/projects/:project_id/subjects/:id/retire     { }
# PUT     pause       /admin/projects/:project_id/subjects/:id/pause      { }
# PUT     resume      /admin/projects/:project_id/subjects/:id/resume     { }


# OK, got it! Wrote SWITCH.py to read in a list of subject IDs, and 
# then make put requests to retire them. 

# First run SWAP with low rejection threshold to get a bunch of
# retirements to do:

SWAP.py CFHTLS-SWITCH-test.config 

# SWAP: interpreting classifications...
# SWAP: 
# SWAP: total no. of classifications processed:  37
# SWAP: saving newly retired subject IDs...
# SWAP: 19 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt

# Good - now SWITCH them:

set retirees = /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt

# SWITCH: retiring subjects listed in  /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt
# SWITCH: looks like we have 19  subjects to retire
# SWITCH: doing a dry run
# result = client.put('/projects/spacewarp/subjects/ASW000075q/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000arx/retire')
# result = client.put('/projects/spacewarp/subjects/ASW00005js/retire')
# result = client.put('/projects/spacewarp/subjects/ASW000082p/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000hlt/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000by9/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000a4m/retire')
# result = client.put('/projects/spacewarp/subjects/ASW00008wq/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000wlr/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000c6t/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000w51/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000kx4/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000s3v/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000l4y/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000d6r/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000b6n/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000tc7/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000hs9/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000kig/retire')

# OK, looks good - give it a try!

SWITCH.py $retirees

# Whoah - success?
# 
# SWITCH: retiring subjects listed in  /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt
# SWITCH: looks like we have 19  subjects to retire
# 
# ...
# 
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(0)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(1)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(2)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(3)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(4)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(5)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(6)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(7)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(8)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(9)
# ASW0000kig False
# ======================================================================

# Check with Michael!! :-)

# Yep, all good after changing response.json to response.json()

# ======================================================================
# 2013-05-08 (Wednesday) 14:29 BST

# Launch day! :-)
# First batch of classifications from Michael. First tidy away all the
# beta work... and also the SWITCH test:

mkdir -p Beta
mv *beta* Beta/
mv spacewarps-2013-04-06_20-07-28* Beta/

mkdir -p SWITCH-test
mv *-SWITCH* SWITCH-test/
mv spacewarp_* SWITCH-test/
mv CFHTLS* SWITCH-test/

# Now make a working directory:
mkdir -p 2013-05-08
cd 2013-05-08

# OK, get new db:

set url = "https://zooniverse-code.s3.amazonaws.com/databases/2013-05-08/ouroboros_projects/spacewarp_2013-05-08.tar.gz?AWSAccessKeyId=AKIAJHHZ7KLFECQKTS7A&Expires=1368612013&Signature=QRK%2BOV37H6khTqgqoTu0z%2FLO%2F2s%3D"

set dbfile = `echo "$url" | cut -d '?' -f1 | cut -d'/' -f7`
set logfile = ${dbfile:r:r}.wget.log
wget -O $dbfile "$url" >& $logfile

# OK, SWIPE this:

SWIPE.csh $dbfile

# Good! This script should write a config file.

SWAP.py startup.config

# Nice - 10,000 classifications of 8000 subjects by 300 people. Crowd
# look very similar to beta! Result :-)

# ======================================================================
# 2013-05-09 (Thursday) 09:46 BST

# Gosh - half a million classifications in the first day!
# Better get this code working at scale - and fast.

# OK, SWAPSHOP is operational and checked in.

# Run on 1st 300,000 classifications!
# Just did:

SWAPSHOP.csh

# Got 117 candidates and 131 false negatives from first 300,000 
# classifications, in 2013-05-09

# Made plot of just false negatives for AV - quite some uncertainty,
# subjects move back and forth quite a lot. Agents are overconfident!


# Try shifting thresholds to 0.4 and 1e-7 (symmetrical). How many
# retirements? Completeness stats?

# Edited swap/startup.config, then ran:

time SWAPSHOP.csh -s CFHTLS-strict -f --fast

# --fast is no animation, so no plots until the end!

# Looks like its about 20s per batch, increasing with time though. 
# 11 batches total, plus plots, takes 8.5 mins.

# STill getting 17% false negatives, and with only 18000 retirements!


# Try a cheap version of Surhud's idea - ignore the first few clicks?
# Coded as ignore if agent.NT <= a_few_at_the_start where this 
# refers to a few training images. Lets try an extreme version with
# a_few_at_the_start = 10!

time SWAPSHOP.csh -s CFHTLS-reallystrict -f --fast

# Same number of classifiers/agents, but now many will stay at 0.5
# because they never leave... 10 training images requires about 30
# images total in the standard stream. The agent history only gets
# updated for classifications that count

# OK, I get 11500 retirements, and down to 13% false negatives
# The total number of classifications is now 267000, so we lose about
# 100k to the traiing programme! Candidates are still at 96, as with
# strict routine.

# Look at the images! Well, ones that are still negative:

mkdir training_false_negatives
set repo = ../2013-05-09/training_false_negatives

foreach url ( `cat CFHTLS-reallystrict_2013-05-09_01:38:24/CFHTLS-reallystrict_2013-05-09_01:38:24_training_false_negatives.txt` )
    set png = $url:t
    cp $repo/$png training_false_negatives/.
end

# OK, we had all but 3 already.
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb2102190044e2.png: No such file or directory
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb210219007187.png: No such file or directory
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb210219004b03.png: No such file or directory

# What do *these* look like?

# Mostly LRGs with rings hidden in depths. All fairly tricky.
# ======================================================================

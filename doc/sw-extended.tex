%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Space Warps System Paper
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[useAMS,usenatbib,a4paper]{mn2e}
%% letterpaper
%% a4paper

\voffset=-0.6in

% Packages:
\input psfig.sty
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}

% Macros:
\input{macros.tex}
\input{addresses.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[\sw]
{\SW Extended! Snappy Titles!}
    
\author[Davis et al.]{%
  \input{sw-system-authors.tex}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
             
\date{to be submitted to ?!?!}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}\pubyear{2014}

\maketitle           

\label{firstpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract} 

\todo{Chris}{Do abstract!}

\end{abstract}

% Full list of options at http://www.journals.uchicago.edu/ApJ/instruct.key.html

\begin{keywords}
  gravitational lensing   --
  methods: statistical    --
  methods: citizen science
\end{keywords}

\setcounter{footnote}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}


% \section{Introduction}
% \label{sec:intro}
% \section{Offline \SW}
% \label{sec:offline}
% \subsection{Formalism}
% \label{sec:offline:formalism}
% \subsection{Training}
% \label{sec:design:training}
% \section{Results}
% \label{sec:results}
% \section{Discussion}
% \label{sec:discuss}
% \section{Conclusions}
% \label{sec:conclude}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO:
% Kamal Nigam, Andrew McCallum and Tom Mitchell. Semi-supervised Text Classification Using EM. In Chapelle, O., Zien, A., and Scholkopf, B. (Eds.) Semi-Supervised Learning. MIT Press: Boston. 2006.
% according to
% http://www.mblondel.org/journal/2010/06/21/semi-supervised-naive-bayes-in-python/#more-126
% this paper would be an example of the sort of thinking I had with the EM
% algorithm (not quite what was implimented in stage 2 at phil's request),
% where the E step just does the unlabeled, and the M step uses both labeled
% and unlabeled data

\section{Formalism}
\label{sec:formalism}

\todo{Chris}{This section will describe the different ways we can use the data
  we got from SpaceWarps to do a beter job with classifications. So we can then
  look at the way SpaceWarps updates the PL, PD, and p's of the objects, either
  via offline, using both/either/neither training and test data (in either online or offline
contexts), manipulating initializations, etc. We could also see what the
benefits are for using the known lens information. Finally, we should examine the
benefits of using a validation dataset (using information we already have!) to
improve our estimates.}

\sw keeps track of the following parameters:
\begin{itemize}
  \item{$x_{ij}$, the classification the $i$-th volunteer made of the $j$-th
      image. $x_{ij}$ may take on three values:
      0, 1, or empty. Since volunteers do not see most images, the vast
    majority of $x_{ij}$ are blank.}
    \item{$PD_{i}$, the probability, given that the image is a dud, that
        $i$-th the volunteer will classify it as a dud. The
      probability, given that the image is a dud, that the volunteer will
    classify it as a lens follows as $1 - PD_{i}$.}
  \item{$PL_{i}$, the probability, given that the image is actually a
      lens, that the $i$-th volunteer will classify it as being a lens. The
      probability, given that the image is a lens, that the volunteer will
    classify it as a dud follows as $1 - PL_{i}$.}
  \item{$p_j$, the probability that
      the $j$-th image $z_{j}$ is a lens given the current observations and skills of the
  volunteers who classified it.}
  \item{$p^{0}$, the prior probability that an object is a lens.}
\end{itemize}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{The Online System}
\label{sec:formalism:online}
In \sw, this is fixed at $2 \times 10^{-4}$, or the expectation that
around 100 lenses will be found in 430,000 images. Because \sw is an online
system that constantly reevaluates most of the above parameters (except $p_0$
and any non-blank $x_{ij}$) in order to promote likely lenses\footnote{Note
that this does not change the probability that a volunteer will actually draw
said image.} or to retire likely duds,\footnote{Images whose probability of
being a lens drops below a certain threshold are removed from the active
dataset.} we augment $p$, $PL$, and $PD$ as $p_j^k$, the evaluation of
$p_j$ at time $k$. \sw uses Bayes' Theorem to update $p_j^{(k + 1)}$ for
some new evaluation $x_{ij}$\footnote{There is no superscript for $x_{ij}$
because each user only sees an image once.}:
\begin{align}
  p_j^{(k + 1)} &= \left ( \frac{x_{ij} PL_{i}^{k}
  }{PL_{i}^{k} p_j^k + (1 - PD_{i}^{k})(1 -
  p_j^k)}
  \right. \notag \\ & \; \left . +
  \frac{(1 - x_{ij}) (1 - PL_{i}^{k})
  }{(1 - PL_{i}^{k}) p_j^k + PD_{i}^{k}(1 -
  p_j^k)} \right ) p_j^k \ ,
\end{align}
The first term on the right hand side is the probability update for evaluating
the object to be a lens, while the second term is the probability that the
image is a lens if the volunteer evaluates it to be a dud.  (For example, an
obtuse volunteer who always perfectly incorrectly classifies an image will
actually change the probability exactly the same as one who always perfectly
correctly classifies an image, given that the estimate of the obtuse
volunteer's skill ($PL_{i} = 0$) is accurate.)

\sw only updates the volunteer's $PL_{i}$ and $PD_{i}$ after volunteer $x_i$
classifies a training image:

\begin{align}
  PL_{i}^{(k + 1)} &= \frac{PL_{i}^{k} (NL_{i}^{k} + M) + \mathbb{I}[x_{ij} =
  z_{j}]}{NL_{i}^{k} + M + 1} \\
  PD_{i}^{(k + 1)} &= \frac{PD_{i}^{k} (ND_{i}^{k} + M) + \mathbb{I}[x_{ij} =
  z_{j}]}{ND_{i}^{k} + M + 1}
\end{align}
where $ND_{i}^{k}$ and $NL_{i}^{k}$ refer to the number of training lenses and
training duds observed by the $i$-th volunteer at time $k$, $z_{j}$ refers
to the true state of the $j$-th image, and $M = 4$ is a smoothing factor
empirically derived to smooth the skill classification of new volunteers.

With these update rules plus an initialization of $PD_{i} = PL_{i} = 0.5$ and
$p^{0} = 2 \times 10^{-4}$, the online update system is fully specified.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{An Offline Expectation Maximization Approach}
\label{sec:formalism:em}
Using the above notation but expanding $p^{0}$ to $p_{ij}^{0}$ (allowing, e.g. for
the distribution of training images to differ for each volunteer, perhaps based on
the number of images they have observed, or to allow a particular image to be
more likely to be drawn), the complete log-likelihood for this model may be
specified:
\begin{multline}
  \mathrm{CLL}(x_{ij}, z_{j}, PL_{i}, PD_{i}, p_{ij}^{0}) \\ = \sum_{i} \sum_{j \in \Omega_i} x_{ij} z_{j} \log PL_{i} +
      (1 - x_{ij}) z_j \log (1 -
      PL_{i}) \\ + (1 - x_{ij}) (1 - z_j) \log PD_{i} + x_{ij} (1 - z_j) \log (1 - PD_{i}) \\ + z_j \log p_{ij}^{0} +
      (1 - z_j ) \log(1 - p_{ij}^{0})
\end{multline}
where $\Omega_i$ is the set of all images volunteer $i$ has observed in $\Omega$,
the set of all images in the program.\footnote{Because the probability that a
  viewer views a given image (given it is a training or test image) is random,
I choose to simply ignore the unobserved images.} We can use this complete
log-likelihood to derive an offline expectation maximization algorithm for
determining the lens probabilities, user skills, and lens priors.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsubsection{E-Step}
\label{sec:formalism:em:estep}
% TODO: reword. The maximization here is over the zj's, so word to make that clear.
% The E-Step is just taking the expected complete log-likelihood, or the
% expectation value over $P(\cdot \ | x, \phi)$.
The E-Step is maximizing the complete log-likelihood with respect to the image
probability $p_j$.  This is equivalent to replacing $z_j$ with $p_j$:
% TODO: replace this with equivalent like eq1
\begin{align}
  p_j &= \frac{1}{N_j} \sum_{i \in \Omega_j} P(z_j = 1 \ | \ x_{ij} ; \Phi) =
  \frac{1}{N_j} \sum_{i \in \Omega_j} \frac{ P(x_{ij} \ | \ z_j = 1; \Phi)
P(z_j = 1 ; \Phi)}{P(x_{ij} ; \Phi)} \\
&= \frac{1}{N_j} \sum_{i \in \Omega_j} \frac{ PL_{i}^{x_{ij}} (1 - PL_{i})^{(1 -
x_{ij})} p_{ij}^{0}}{ PL_{i}^{x_{ij}} (1 -
  PL_{i})^{(1 - x_{ij})} p_{ij}^{0} + PD_{i}^{(1 - x_{ij})} (1 -
PD_{i})^{x_{ij}} (1 - p_{ij}^{0})}
\end{align}
where $i \in \Omega_j$ is now the set of classifications done on the $j$-th
image and $N_j$ is the number of classifications done on the $j$-th image. This
makes sense: $p_{ij}^{0}$ is just the prior likelihood of an image being a lens,
while $PL_{i}$ is how well we would have identified a lens as such.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsubsection{M-Step}
\label{sec:formalism:em:mstep}
The M-Step is done by maximizing the expected complete log-likelihood with
regard to the input parameters $PD_{i}, PL_{i}, p_{ij}^{0}$. Doing the
maximization process, we find:
\begin{align}
  PL_{i} &= \frac{\sum_{j \in \Omega_i} x_{ij} p_{j}}{\sum_{j \in
\Omega_i} p_{j}} \\
  PD_{i} &= \frac{\sum_{j \in \Omega_i} (1 - x_{ij}) (1 - p_{j})}{\sum_{j \in
\Omega_i} (1 - p_{j})}
\end{align}
\begin{align}
  p_{ij}^{0} &= p_{j} \ , &p_{i}^{0} = \frac{\sum_{j \in \Omega_i}
p_{j}}{\sum_{j \in \Omega_i} 1} \notag\\
   p_{j}^{0} &= p_{j} \ , &p^{0} = \frac{\sum_i \sum_{j \in \Omega_i}
p_{j}}{\sum_i \sum_{j \in
  \Omega_i} 1} \ ,
\end{align}
where the possible specializations of $p_0$ are also given. These mirror quite
closely the online systems, except that skill is now assessed against
the majority expectation of the probability of an image being a lens, instead
of its true value.

In practice we have training images where $p_{j}$ is known. In those
cases we can use the true value when doing the M-Step.

Finally, we also include Laplace smoothing into the M-Step in order to handle
pathologic cases, such as when users never identify any lenses ($\sum_{j \in
\Omega_{i}} p_j = 0$). The estimators for $PL_{i}$ and $PD_{i}$ now become:
\begin{align}
  PL_{i} &= \frac{M + \sum_{j \in \Omega_i} x_{ij} p_{j}}{2M + \sum_{j \in
\Omega_i} p_{j}} \\
  PD_{i} &= \frac{M + \sum_{j \in \Omega_i} (1 - x_{ij}) (1 - p_{j})}{2M + \sum_{j \in
\Omega_i} (1 - p_{j})}
\end{align}
where for Laplace smoothing, $M = 1$.

We choose to specialize $p^{0}$ to vary with
image, $p_{j}^{0}$, because images are taken out of the \sw system if they reach
too low a probability, clearly changing the prior when we evaluate at the end
of the run; training images also have a
different prior on being a lens as well. Finally, if the image is a training
image with known $p_j \in (0,1)$, then the known $p_j$ is used instead of
the current estimate.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Validation of Training}
\label{sec:validation}

\todo{Chris}{In order to look at a validation dataset, I need to create a
  blacklist of agents and subjects (and decide what sort of division of either
/ both / neither constitutes a good validation dataset here) that SWAP.py can
then read in and process.}

A validation dataset is needed to prevent overfitting training data and to try
to test how the training data does against real lenses. These need to come in
two categories: actual lens environments, and simulated lenses. The need for
two sets arises because of the paucity of actual lenses. In \SW, most training
objects are explicitly given to a user -- if a user incorrectly identifies a
training object, they are informed of that failure, and likewise for a correct
classification.

Problems:
0. By telling users about failures in the sim/dud, we explicitly break the
notion that users come in fully-formed. But we also need to give users
incentives to keep working, by rewarding them for good behavior. Replace by
current crowd assessments and telling them how they did compared with the
crowd?
1. \SW does not have any 'silent' training images which could function as
validation datasets, since you have broken the training by telling users.
2. How to manage the difference between 'dud known lens fields' and 'dud sim
fields'? Just put them together?
3. If you tell users about the correct sim classification, do you also tell
them about a correct lens classification, and do you tell them it was a real
lens?
4. Can I just use the dud fields?

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Dynamic Allocations}
\todo{Chris}{This section will examine whether we would be better off
  dynamically assigning images to people (based on current estimates of skill
  and probability) rather than randomly assigning them. This means I will need
  to create some sort of 'SpaceWarps Emulator'. (Actually, the other thing
  I can do is use the blacklist developed earlier to throw out
  contributions in an informed manner in order to construct different
  simulations.) Before I even do that, another
aspect I would like to examine and is probably useful is whether we can
reliably identify skilled users early on. That is, instead of looking at final
skill vs effort, look at many trajectories of skill vs effort over time. That
would be a useful thing to show to prove that we can find the good users in the
first place -- early on!}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure*}
% %\centering\includegraphics[width=0.9\linewidth]{sw-system-figs/sw-screengrab-marker+feedback.png}
% \caption{Screenshot of the \sw classification interface.}
% \label{fig:screenshot}
% \end{figure*}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  ACKNOWLEDGMENTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}
 
\input{acknowledgments.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% MNRAS does not use bibtex, input .bbl file instead. 
% Generate this in the makefile using bubble script in scriptutils:

% bubble -f paper-lcr.tex references.bib 
% \input{paper-lcr.bbl}

\bibliographystyle{apj}
\bibliography{references}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{lastpage}
\bsp

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
